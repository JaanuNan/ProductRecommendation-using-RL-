# ProductRecommendation-using-RL

ğŸ›’ RL Product Recommendation in Online Advertising ğŸ¤–



Overview:

--------

This application showcases the power of Reinforcement Learning (RL) for suggesting products in online advertising. ğŸ’¡ It simulates how users interact with recommendations and trains intelligent agents to make the best suggestions based on user profiles and their feedback. ğŸ§ 



ğŸš€ Try the live application here: https://3txizagfu9hmhe6p9dpe5h.streamlit.app/ ğŸŒ



Key Features:

-------------

- **Algorithm Selection:** Choose your recommendation strategy! ğŸ¤” Options include Multi-Armed Bandit (Epsilon-Greedy), Q-Learning, Deep Q-Learning (DQN), and Actor-Critic.

- **Simulated User Profiles:** Explore recommendations for diverse virtual users ğŸ‘¤ with unique preferences, purchase histories ğŸ›ï¸, demographics ğŸ“Š, and interests.

- **Agent Training:** Watch the magic happen! âœ¨ Train the selected RL agent by setting the number of simulation rounds ğŸ”„.

- **Product Recommendations:** Get personalized suggestions! ğŸ The trained agent will recommend the most promising products.

- **User Feedback:** Your opinion matters! ğŸ‘ Rate the recommendations to help the agent learn and improve.

- **Performance Visualization:** See how the agent learns! ğŸ“ˆ Track its progress with average reward charts.

- **Policy Inspection:** Peek into the agent's mind! ğŸ‘€ Examine the learned Q-values (Q-Learning) and recommendation probabilities (Actor-Critic).

- **User Demographics Analysis:** Understand your virtual audience! ğŸ§‘â€ğŸ¤â€ğŸ§‘ Visualize user distribution by age ğŸ‚, occupation ğŸ’¼, and location ğŸ“.

- **Product Exploration:** Discover the items! ğŸ” View details and images ğŸ–¼ï¸ of all available products.

- **Simplified Profile Editing:** Experiment with user preferences! âœï¸ Make quick changes to see how recommendations adapt.

- **Simulated CTR:** Get a glimpse of engagement! ğŸ–±ï¸ Observe a sample Click-Through Rate (CTR) table for different products.



Technologies Used:

------------------

- Streamlit: Building the interactive web interface. ğŸ’»

- NumPy: Number crunching and array wizardry. <0xF0><0x9F><0xA7><0xAE>

- PyTorch: Powering the advanced RL models (DQN, Actor-Critic). ğŸ”¥

- Matplotlib: Creating static charts (for Q-Learning insights). ğŸ“Š

- Pandas: Managing and manipulating data tables. ğŸ¼

- Seaborn: Enhancing data visualization with style. ğŸ¨

- Plotly Express: Making interactive and dynamic charts. ğŸ“Šâœ¨



How to Use (via the Streamlit App):

-----------------------------------

1. **Select an Algorithm:** Head to the sidebar and pick your recommendation algorithm. ğŸ¤”

2. **Select a User:** Choose a user from the dropdown to see tailored suggestions. ğŸ‘¤

3. **Train Agent (Optional):** Set the training episodes and hit "Train Agent" to start the learning process. ğŸš€

4. **View Recommendation:** The top recommendation for the current user will appear. ğŸ

5. **Provide Feedback:** Rate the suggestion using the slider and click "Submit Feedback." ğŸ‘ğŸ‘

6. **Explore Visualizations:** Check out the performance graphs, Q-tables, and probability charts. ğŸ“ˆğŸ“Š

7. **Interact with Other Features:** Dive into user profiles, product details, and the CTR table. ğŸ”



Local Setup (for development or running locally):

------------------------------------------------

1. **Make sure you have Python 3.x installed.** ğŸ

2. **Install the necessary libraries:**
Plaintext

ğŸ›’ RL Product Recommendation in Online Advertising ğŸ¤–

Overview:
--------
This application showcases the power of Reinforcement Learning (RL) for suggesting products in online advertising. ğŸ’¡ It simulates how users interact with recommendations and trains intelligent agents to make the best suggestions based on user profiles and their feedback. ğŸ§ 

ğŸš€ Try the live application here: https://3txizagfu9hmhe6p9dpe5h.streamlit.app/ ğŸŒ

Key Features:
-------------
- **Algorithm Selection:** Choose your recommendation strategy! ğŸ¤” Options include Multi-Armed Bandit (Epsilon-Greedy), Q-Learning, Deep Q-Learning (DQN), and Actor-Critic.
- **Simulated User Profiles:** Explore recommendations for diverse virtual users ğŸ‘¤ with unique preferences, purchase histories ğŸ›ï¸, demographics ğŸ“Š, and interests.
- **Agent Training:** Watch the magic happen! âœ¨ Train the selected RL agent by setting the number of simulation rounds ğŸ”„.
- **Product Recommendations:** Get personalized suggestions! ğŸ The trained agent will recommend the most promising products.
- **User Feedback:** Your opinion matters! ğŸ‘ Rate the recommendations to help the agent learn and improve.
- **Performance Visualization:** See how the agent learns! ğŸ“ˆ Track its progress with average reward charts.
- **Policy Inspection:** Peek into the agent's mind! ğŸ‘€ Examine the learned Q-values (Q-Learning) and recommendation probabilities (Actor-Critic).
- **User Demographics Analysis:** Understand your virtual audience! ğŸ§‘â€ğŸ¤â€ğŸ§‘ Visualize user distribution by age ğŸ‚, occupation ğŸ’¼, and location ğŸ“.
- **Product Exploration:** Discover the items! ğŸ” View details and images ğŸ–¼ï¸ of all available products.
- **Simplified Profile Editing:** Experiment with user preferences! âœï¸ Make quick changes to see how recommendations adapt.
- **Simulated CTR:** Get a glimpse of engagement! ğŸ–±ï¸ Observe a sample Click-Through Rate (CTR) table for different products.

Technologies Used:
------------------
- Streamlit: Building the interactive web interface. ğŸ’»
- NumPy: Number crunching and array wizardry. <0xF0><0x9F><0xA7><0xAE>
- PyTorch: Powering the advanced RL models (DQN, Actor-Critic). ğŸ”¥
- Matplotlib: Creating static charts (for Q-Learning insights). ğŸ“Š
- Pandas: Managing and manipulating data tables. ğŸ¼
- Seaborn: Enhancing data visualization with style. ğŸ¨
- Plotly Express: Making interactive and dynamic charts. ğŸ“Šâœ¨

How to Use (via the Streamlit App):
-----------------------------------
1. **Select an Algorithm:** Head to the sidebar and pick your recommendation algorithm. ğŸ¤”
2. **Select a User:** Choose a user from the dropdown to see tailored suggestions. ğŸ‘¤
3. **Train Agent (Optional):** Set the training episodes and hit "Train Agent" to start the learning process. ğŸš€
4. **View Recommendation:** The top recommendation for the current user will appear. ğŸ
5. **Provide Feedback:** Rate the suggestion using the slider and click "Submit Feedback." ğŸ‘ğŸ‘
6. **Explore Visualizations:** Check out the performance graphs, Q-tables, and probability charts. ğŸ“ˆğŸ“Š
7. **Interact with Other Features:** Dive into user profiles, product details, and the CTR table. ğŸ”

Local Setup (for development or running locally):
------------------------------------------------
1. **Make sure you have Python 3.x installed.** ğŸ
2. **Install the necessary libraries:**
pip install -r requirements.txt

(Ensure your `requirements.txt` file in the project root looks something like this:
streamlit
numpy
torch
matplotlib
pandas
seaborn
plotly

)
3. **Run the Streamlit app:**
streamlit run app.py


Further Enhancements (Potential Future Work):
---------------------------------------------
- Develop more intricate user behavior and preference models. ğŸ§ 
- Create a more realistic and dynamic simulation environment. ğŸŒ
- Explore and integrate even more cutting-edge RL algorithms. ğŸ”¬
- Add metrics to evaluate recommendation quality offline. ğŸ“Š
- Implement A/B testing features to compare strategies. ğŸ§ª
- Enable real-time recommendation updates based on user actions. â±ï¸
- Integrate with a more comprehensive simulated e-commerce platform. ğŸ›’ğŸ’»

Contributing:
-------------
We welcome your ideas and contributions! ğŸ™ Feel free to suggest improvements or report any issues.

License:
--------
MIT License

Copyright (c) 2025 Janani N

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
